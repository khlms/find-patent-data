<section itemprop="description" itemscope="">
<h2>Description</h2>
<div html="" itemprop="content"><div class="description" lang="EN" load-source="patent-office" mxw-id="PDES200776955">
<heading id="h-0001">CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
<p id="p-0002" num="0001">This application is a continuation of U.S. patent application Ser. No. 15/006,449, filed Jan. 26, 2016, which is a continuation of U.S. patent application Ser. No. 13/780,493 filed Feb. 28, 2013, which is a divisional of U.S. patent application Ser. No. 12/368,014 filed Feb. 9, 2009, now U.S. Pat. No. 8,493,436, issued Jul. 23, 2013, which claims the benefit of U.S. Provisional Appl. No. 61/027,237, filed Feb. 8, 2008, the disclosures of which are incorporated herein by reference.</p>
<heading id="h-0002">BACKGROUND</heading>
<heading id="h-0003">Field</heading>
<p id="p-0003" num="0002">The present invention relates to the field of panoramic still and motion photography.</p>
<heading id="h-0004">Related Art</heading>
<p id="p-0004" num="0003">Imaging systems exist that include more than one camera in a rosette formation attached to a vehicle. Those imaging systems may be used to capture panoramic images, for example, along a street. Each camera includes an entrance pupil. Having multiple entrance pupils at different locations can cause spatial parallax. Parallax refers to a perceived shift of an imaged object against a background caused by the different viewpoints of the entrance pupils of the cameras. Parallax is a particular problem when stitching together images from multiple cameras, since it can cause ghosting of foreground objects when background objects are aligned in the region where adjacent images overlap.</p>
<p id="p-0005" num="0004">Mirrors have been used to avoid parallax in panoramic imaging. For example, Disney's Circle-Vision 360° system uses mirrors to view the world through multiple co-located entrance pupils. This can result in zero parallax. However, making and using the necessary large mirrors is difficult. Also, this technique limits the vertical field of view.</p>
<p id="p-0006" num="0005">Each camera in the rosette formation includes an image sensor that converts an optical signal into an electrical signal to form an image. Two types of image sensors avoid the need for a mechanical shutter—an interline-shutter charge-coupled device (CCD) or a complementary metal oxide semiconductor (CMOS) sensor.</p>
<p id="p-0007" num="0006">The CMOS sensor typically has a rolling shutter, which exposes different lines of the scene at slightly different times, in a sequence that rolls across the image. The rolling shutter can lead to image distortion, such as warping, when the camera is moving relative to the scene or subject. Some work has been done to compensate for the image distortion. Wilburn et al. describes using a rolling shutter timing offset to process and correct distortions induced by motion of a subject of an image. See Wilburn et al., “High-Speed Videography Using a Dense Camera Array”, 2004 <i>IEEE Computer Society Conference on Computer Vision and Pattern Recognition </i>(<i>CVPR'</i>04), Vol. 2, pp. 294-301.</p>
<p id="p-0008" num="0007">The interline-shutter CCD avoids the image distortion issues of the rolling shutter CMOS sensor. However, the interline-shutter CCD can suffer from blooming and streaking. Blooming and streaking occur when a portion of the sensor is over-exposed, causing light to spillover to adjacent pixels or into the readout CCD structure.</p>
<p id="p-0009" num="0008">What is needed is an imaging apparatus that reduces distortion and spatial parallax, while avoiding the blooming and streaking issues associated with CCDs.</p>
<heading id="h-0005">BRIEF SUMMARY</heading>
<p id="p-0010" num="0009">The present invention relates to the field of panoramic still and motion photography. In a first embodiment, a camera apparatus for panoramic photography includes a first image sensor positioned to capture a first image. The first image sensor has a rolling-shutter readout arranged in portrait orientation. The camera apparatus also includes second image sensor positioned to capture a second image. The second image sensor has a rolling-shutter readout arranged in portrait orientation. Finally, the camera apparatus includes a controller configured to signal the second image sensor to start capturing the second image before the first image sensor finishes capturing the first image. At least a portion of the first image is in front of the second image relative to a forward direction of the camera apparatus.</p>
<p id="p-0011" num="0010">In a second embodiment, a method for panoramic photography includes the steps of: capturing a first image with a first image sensor and starting to capture a second image with a second image sensor prior to completion of the capturing of the first image. The first and second image sensors have a rolling-shutter readouts arranged in landscape orientation. At least a portion of the first image is in front of the second image relative to a forward direction of a camera apparatus comprising the first and second image sensors.</p>
<p id="p-0012" num="0011">In a third embodiment, a camera apparatus for motion photography includes a first camera having a first entrance pupil. During forward motion of the camera apparatus, the first camera captures a first image. A camera apparatus also includes a second camera having a second entrance pupil. During the forward motion of the camera apparatus, the second camera captures a second image. Motion of the camera apparatus results in motion parallax. The timing of when the first camera captures a first image relative to when the second camera captures the second image uses the motion parallax to reduce the effect of spatial parallax between the first camera and the second camera.</p>
<p id="p-0013" num="0012">In a fourth embodiment, a method for motion photography with a camera apparatus includes: capturing a first image with a first camera in the camera apparatus at a first time during forward motion of the camera apparatus, and capturing a second image with a second camera in the camera apparatus at a second time the during forward motion of the camera apparatus. Motion of the camera apparatus results in motion parallax. The timing of when the capturing (a) occurs relative to when the capturing (b) occurs uses the motion parallax to reduce the effect of spatial parallax between the first camera and the second camera.</p>
<p id="p-0014" num="0013">In this way, embodiments of the present invention reduce distortion and spatial parallax.</p>
<p id="p-0015" num="0014">Further embodiments, features, and advantages of the invention, as well as the structure and operation of the various embodiments of the invention are described in detail below with reference to accompanying drawings.</p>
<description-of-drawings>
<heading id="h-0006">BRIEF DESCRIPTION OF THE FIGURES</heading>
<p id="p-0016" num="0015">The accompanying drawings, which are incorporated herein and form a part of the specification, illustrate the present invention and, together with the description, further serve to explain the principles of the invention and to enable a person skilled in the pertinent art to make and use the invention.</p>
<p id="p-0017" num="0016"> <figref idrefs="DRAWINGS">FIG. 1A</figref> includes a diagram illustrating a camera that includes a rolling-shutter CMOS sensor.</p>
<p id="p-0018" num="0017"> <figref idrefs="DRAWINGS">FIG. 1B</figref> includes a diagram illustrating a camera having a rolling-shutter CMOS sensor with groups of photodiodes arranged in columns substantially perpendicular to the ground, according to an embodiment of the present invention.</p>
<p id="p-0019" num="0018"> <figref idrefs="DRAWINGS">FIGS. 2A-C</figref> include diagrams illustrating a portion of a camera rosette which may be used in panoramic imaging, according to an embodiment of the present invention.</p>
<p id="p-0020" num="0019"> <figref idrefs="DRAWINGS">FIG. 3</figref> includes a diagram showing the operation of the camera rosette shown in <figref idrefs="DRAWINGS">FIGS. 2A-C</figref> in further detail.</p>
<p id="p-0021" num="0020"> <figref idrefs="DRAWINGS">FIGS. 4A-B</figref> show how positioning of the entrance pupils of a camera impacts parallax.</p>
<p id="p-0022" num="0021"> <figref idrefs="DRAWINGS">FIG. 5</figref> shows a diagram illustrating timing the exposure of cameras in a camera rosette to reduce spatial parallax, according to an embodiment of the present invention.</p>
<p id="p-0023" num="0022"> <figref idrefs="DRAWINGS">FIG. 6</figref> shows a diagram of a camera rosette affixed to a vehicle.</p>
</description-of-drawings>
<p id="p-0024" num="0023">The drawing in which an element first appears is typically indicated by the leftmost digit or digits in the corresponding reference number. In the drawings, like reference numbers may indicate identical or functionally similar elements.</p>
<heading id="h-0007">DETAILED DESCRIPTION OF EMBODIMENTS</heading>
<p id="p-0025" num="0024">Embodiments of present invention reduce distortion and spatial parallax in panoramic images taken from a camera rosette affixed to a vehicle. Each camera in the camera rosette includes an image sensor. The image sensor may expose to capture an image while the vehicle is moving. This movement can cause distortion in the resulting image. In an embodiment of the present invention, the CMOS sensor is arranged in “portrait” orientation. As is described in detail below, this reduces the image distortion.</p>
<p id="p-0026" num="0025">Having multiple cameras in different locations on the camera rosette can cause spatial parallax. In a further embodiment of the present invention, the motion parallax of the vehicle is employed to cancel out spatial parallax. In that embodiment, as the vehicle moves, exposure of the cameras in the camera rosette is timed such that the entrance pupils of the cameras are in approximately the same location when each sensor is exposed. This embodiment is described in detail below.</p>
<p id="p-0027" num="0026">In the detailed description of the invention that follows, references to “one embodiment”, “an embodiment”, “an example embodiment”, etc., indicate that the embodiment described may include a particular feature, structure, or characteristic, but every embodiment may not necessarily include the particular feature, structure, or characteristic. Moreover, such phrases are not necessarily referring to the same embodiment. Further, when a particular feature, structure, or characteristic is described in connection with an embodiment, it is submitted that it is within the knowledge of one skilled in the art to effect such feature, structure, or characteristic in connection with other embodiments whether or not explicitly described.</p>
<p id="p-0028" num="0027">The term “camera rosette” used herein refers to two or more cameras arranged to capture a panoramic image. Each camera captures an image. The images may be stitched together to form the panoramic image. This stitching may, for example, be done by well-known software techniques.</p>
<p id="p-0029" num="0028">The term “camera” used herein refers to a device that captures a photographic image. A camera includes an image sensor, and a lens having an entrance pupil.</p>
<p id="p-0030" num="0029">The term “image sensor” used herein refers to a device that converts optical signals into electrical signals to capture an image when exposed.</p>
<p id="p-0031" num="0030"> <figref idrefs="DRAWINGS">FIG. 1A</figref> includes a diagram <b>100</b> illustrating a camera that includes a rolling-shutter CMOS image sensor. Diagram <b>100</b> shows a camera and its image sensor at two points in time. At a first point in time, the camera is at a position <b>102</b> and its image sensor is at a position <b>104</b>. At a second point in time, the camera is at a position <b>112</b> and its image sensor is at a position <b>114</b>. The dot in the figure represents the entrance pupil of the lens, and rays are shown projecting through it in the manner of a pinhole camera for simplicity.</p>
<p id="p-0032" num="0031">In an example, the camera may be attached to a vehicle, and movement of the vehicle may have caused the camera to move. As mentioned above, the image sensor may be a rolling shutter CMOS sensor. A rolling shutter CMOS sensor may include groups of photodiodes that capture light and convert the light into electrical signals during exposure. A rolling shutter CMOS sensor may expose different groups of photodiodes at different times. A rolling shutter CMOS sensor has a readout time. The readout time is the time necessary to read out all the groups of photodiodes at the ends of their respective exposure times. In the example shown in <figref idrefs="DRAWINGS">FIG. 1A</figref>, the CMOS sensor is in “landscape” orientation, meaning that the groups of photodiodes are arranged as rows running parallel to the ground.</p>
<p id="p-0033" num="0032">The rolling shutter sensor may be exposed while the vehicle is in motion. In an example, a rolling shutter sensor may require 100 ms of readout time to capture an image. While the image is captured, the vehicle and camera may have moved forward 1 m. The movement causes the objects captured by the image sensor to change as shown at <b>106</b>. This causes distortion in the resulting image. Because different rows of photodiodes in the CMOS sensors are exposed at different times, the image may appear warped, e.g. vertical features may be slanted. An image sensor that does not have a rolling shutter and is exposed in its entirety, such as an interline-shutter CCD sensor, may reduce or avoid warping. However, as mentioned earlier, interline-shutter CCD sensors may suffer from blooming and streaking.</p>
<p id="p-0034" num="0033">To deal with the problem of warping due to rolling shutter sensors, embodiments of the present invention have rolling shutter image sensors arranged in “portrait” orientation as illustrated in <figref idrefs="DRAWINGS">FIG. 1B</figref>. <figref idrefs="DRAWINGS">FIG. 1B</figref> includes a diagram <b>150</b> illustrating a camera having a rolling-shutter sensor, such as a CMOS sensor, in portrait orientation. Portrait orientation means that the groups of photodiodes are arranged in columns running perpendicular to the ground.</p>
<p id="p-0035" num="0034">Diagram <b>150</b> shows a camera at different positions at different points in time. As mentioned earlier, the camera may be affixed to a vehicle, and the vehicle may be in motion. In an embodiment of the invention, the columns of photodiodes are exposed back-to-front in object space and front-to-back in image space.</p>
<p id="p-0036" num="0035">At a position <b>152</b>, the camera exposes a forward-most photodiode column <b>156</b> to capture an image including a back-most field of view <b>154</b>. Then, at a position <b>160</b>, the camera exposes a photodiode column <b>158</b>, which is behind photodiode column <b>156</b>. This exposure captures a field of view <b>172</b>, which is to the front of field of view <b>154</b>. As the camera moves to a position <b>162</b> and a position <b>164</b>, columns continue to expose in a front-to-back manner, which captures objects from back-to-front. Finally, when the camera is at a position <b>166</b>, the camera exposes a back-most photodiode column <b>168</b> to capture an image including a forward-most field of view <b>170</b>.</p>
<p id="p-0037" num="0036">Positioning the image sensor in portrait orientation avoids the warping of vertical features that occurs in landscape orientation. Instead, objects may appear stretched by an amount that depends on their distance. Stretching is not as visually unappealing as warping. In fact, stretching may be a positive feature. Stretching makes foreground objects thinner with respect to background objects, rather than fatter, when the rolling shutter is arranged in the direction described. As result, the foreground objects occlude less of the scene behind them. This may be a benefit in many applications related to panoramic imaging.</p>
<p id="p-0038" num="0037">Panoramic imaging often includes taking images from multiple cameras oriented in different directions. The multiple images may then be stitched together into a panorama using well-known software techniques. When multiple cameras are used in this way, an object may exist in the field of view of more than one camera. In motion photography, objects may move or change over time relative to the cameras. If multiple cameras expose the object at different times, then the object may appear differently in the multiple images to stitch together into a single panorama. The resulting panorama may have ghosting or other undesirable image problems. To deal with this, exposure needs to be coordinated between the multiple cameras to capture objects at the same time or close to the same time. This becomes even more challenging with rolling shutter image sensors because different portions of each image sensor are exposed as different times. To deal with this, embodiments of the present invention time exposure of multiple image sensors as illustrated in <figref idrefs="DRAWINGS">FIGS. 2A-C</figref>.</p>
<p id="p-0039" num="0038"> <figref idrefs="DRAWINGS">FIGS. 2A-C</figref> include diagrams illustrating a portion of a camera rosette, which may be used in panoramic imaging. Each camera in the camera rosette includes a rolling-shutter image sensor, such as a rolling-shutter CMOS sensor, in portrait orientation as described with respect to <figref idrefs="DRAWINGS">FIG. 1B</figref>.</p>
<p id="p-0040" num="0039"> <figref idrefs="DRAWINGS">FIG. 2A</figref> includes a diagram <b>200</b>. Diagram <b>200</b> shows a camera rosette with cameras <b>202</b> and <b>210</b>. For clarity, only two cameras are shown. However, in practice the rosette may contain a different number of cameras. Camera <b>202</b> has photodiode column <b>204</b> exposed to a field of view <b>220</b>.</p>
<p id="p-0041" num="0040"> <figref idrefs="DRAWINGS">FIG. 2B</figref> includes a diagram <b>230</b>. Diagram <b>230</b> shows the rosette shown in <figref idrefs="DRAWINGS">FIG. 2A</figref> at a later point in time. Camera <b>202</b> has a total field of view <b>224</b>, and camera <b>210</b> has a total field of view <b>234</b>. As camera <b>202</b> scans across field of view <b>224</b> back-to-front (in object space), camera <b>202</b> begins to expose photodiode columns from a group of photodiode columns <b>206</b>. Group of columns <b>206</b> captures objects within field of view <b>222</b>. Field of view <b>222</b> overlaps with camera <b>210</b>'s total field of view <b>234</b> for distant objects.</p>
<p id="p-0042" num="0041">When camera <b>202</b> begins to expose photodiode columns from group of columns <b>206</b>, camera <b>210</b> begins to expose photodiode columns from a group of photodiode columns <b>208</b>. Camera <b>210</b> exposes photodiode columns in group of columns <b>208</b> back-to-front (in object space) to capture field of view <b>226</b>. Field of view <b>226</b> overlaps with camera <b>202</b>'s total field of view <b>224</b> for distant objects. Effectively, camera <b>202</b> exposes photodiode columns in group of columns <b>206</b> simultaneously with camera <b>210</b> exposing photodiode columns in group of columns <b>208</b>. When camera <b>202</b> completes exposure of group of columns <b>206</b>, camera <b>202</b> finishes its exposure. However, camera <b>210</b> continues to expose photodiode columns, as shown <figref idrefs="DRAWINGS">FIG. 2C</figref>.</p>
<p id="p-0043" num="0042"> <figref idrefs="DRAWINGS">FIG. 2C</figref> shows a diagram <b>240</b>. Diagram <b>240</b> shows the rosette shown in <figref idrefs="DRAWINGS">FIG. 2B</figref> at a later point in time after camera <b>202</b> has completed its exposure. In diagram <b>240</b>, a photodiode column <b>232</b> is exposed, capturing a field of view <b>228</b>. As camera <b>210</b> continues its exposure, it may overlap with an field of view with another camera (not shown) and the process may continue for an entire camera rosette as is described with respect to <figref idrefs="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0044" num="0043">The embodiment illustrated in <figref idrefs="DRAWINGS">FIGS. 2A-C</figref> is described with respect to an illustrative example. In an example, overlap field of view <b>222</b> for distant objects between camera <b>202</b> and camera <b>210</b> may be 10% of total field of view <b>224</b> of camera <b>202</b>. In that example, the delay between the time when camera <b>202</b> starts exposure and the time when camera <b>210</b> starts exposure may be 90% of camera <b>202</b> readout time. Camera <b>202</b> and <b>210</b> may or may not have the same readout time. In an example where the readout time is 100 ms, the delay between the time when camera <b>202</b> starts exposure and the time when camera <b>210</b> starts exposure may be 90 ms.</p>
<p id="p-0045" num="0044">The camera rosette may have at least one controller that synchronizes the cameras to capture images at specified time offsets. So, the controller may be preprogrammed with the delays indicating when each camera starts to capture an image.</p>
<p id="p-0046" num="0045">In another embodiment, the delay time may be offset according to the vehicle's velocity. As is described below with respect to <figref idrefs="DRAWINGS">FIG. 5</figref>, this has the effect of using motion parallax from movement of the vehicle to cancel out spatial parallax caused by the multiple cameras.</p>
<p id="p-0047" num="0046">As mentioned above, the operation of the two cameras described with respect to <figref idrefs="DRAWINGS">FIGS. 2A-C</figref> may continue through an entire camera rosette. In one embodiment, a camera rosette may have a total of between six and ten cameras, inclusive, positioned to capture a 360 degree panorama. In a preferred embodiment, the camera rosette may have at least eight cameras, such as the rosette illustrated with respect to <figref idrefs="DRAWINGS">FIG. 3</figref>.</p>
<p id="p-0048" num="0047"> <figref idrefs="DRAWINGS">FIG. 3</figref> shows a diagram <b>300</b> illustrating the operation of a camera rosette according to an embodiment of the present invention in further detail. In a preferred embodiment, a camera rosette may include nine cameras—eight in a horizontal ring, and one directed straight up. Diagram <b>300</b> shows the eight horizontal cameras. Each camera in the camera rosette includes a rolling shutter sensor in portrait orientation with columns of photodiodes.</p>
<p id="p-0049" num="0048">The camera rosette begins capturing a panoramic image at the rear-most cameras <b>305</b> and <b>304</b>. Both of the cameras <b>305</b> and <b>304</b> start by exposing the back most photodiodes columns (in object-space) and scan forward as described with respect to <figref idrefs="DRAWINGS">FIG. 1B</figref>. Cameras <b>306</b>, <b>303</b> start capturing images at a time defined by a time delay as described with respect to <figref idrefs="DRAWINGS">FIG. 2B</figref>.</p>
<p id="p-0050" num="0049">The rosette continues to scan forward until the forward-most cameras <b>301</b>, <b>308</b> have completed scanning. Each camera starts at a time defined by the start of the adjacent camera to its rear plus a delay. For example, a camera <b>302</b> starts at a time defined by the start of camera <b>303</b> plus a delay. The delay may correspond to the size of the overlap in the field of view of adjacent cameras, as described with respect to FIG. <b>2</b>B. The delay may also be offset according to the velocity of the vehicle, as is described with respect to <figref idrefs="DRAWINGS">FIG. 5</figref>.</p>
<p id="p-0051" num="0050">Each of the eight cameras in <figref idrefs="DRAWINGS">FIG. 3</figref> is at a different location and has an entrance pupil at a different location. Having entrance pupils at different locations causes spatial parallax as illustrated in <figref idrefs="DRAWINGS">FIGS. 4A-B</figref>.</p>
<p id="p-0052" num="0051"> <figref idrefs="DRAWINGS">FIGS. 4A-B</figref> show how the positioning of the entrance pupils of two cameras impacts spatial parallax. <figref idrefs="DRAWINGS">FIG. 4A</figref> shows an example imaging apparatus <b>400</b>. Imaging apparatus <b>400</b> includes a camera <b>402</b> and a camera <b>404</b>. Camera <b>402</b> has an entrance pupil <b>406</b>, and camera <b>404</b> has an entrance pupil <b>408</b>. Entrance pupil <b>406</b> and entrance pupil <b>408</b> are separated by a distance <b>426</b>. Each camera <b>402</b>, <b>404</b> captures an image including an object <b>410</b>. However there is a wide difference in the background of object <b>410</b> as it appears in cameras <b>402</b>, <b>404</b>. This is shown by the large parallax angle <b>422</b>.</p>
<p id="p-0053" num="0052"> <figref idrefs="DRAWINGS">FIG. 4B</figref> shows an example imaging apparatus <b>450</b>. Imaging apparatus <b>450</b> includes a camera <b>416</b> and a camera <b>414</b>. Camera <b>416</b> has an entrance pupil <b>418</b>, and camera <b>414</b> has an entrance pupil <b>420</b>. Entrance pupil <b>418</b> and entrance pupil <b>420</b> are separated by a distance <b>428</b>. Distance <b>428</b> is shorter than distance <b>426</b> in <figref idrefs="DRAWINGS">FIG. 4A</figref>. Each camera <b>416</b>, <b>414</b> captures an image including an object <b>412</b>. There is a small difference in the background of object <b>412</b> as it appears in cameras <b>416</b>, <b>414</b>, as compared to cameras <b>402</b>, <b>404</b> in <figref idrefs="DRAWINGS">FIG. 4A</figref>. This is shown by the parallax angle <b>424</b>. Therefore, parallax angle <b>422</b> in <figref idrefs="DRAWINGS">FIG. 4B</figref> is less than parallax angle <b>424</b> in <figref idrefs="DRAWINGS">FIG. 4A</figref>.</p>
<p id="p-0054" num="0053">Thus, two cameras being in different places can cause spatial parallax. Similarly, motion parallax is caused by a camera being in different locations at different times. According to an embodiment of the present invention, motion parallax caused by motion of a camera rosette by cancel out or reduce the effect of spatial parallax caused by the entrance pupils of the different cameras on the camera rosette being located at different locations. This embodiment is illustrated in <figref idrefs="DRAWINGS">FIG. 5</figref>.</p>
<p id="p-0055" num="0054"> <figref idrefs="DRAWINGS">FIG. 5</figref> shows a diagram <b>500</b> illustrating timing the exposure of cameras in a camera rosette to reduce parallax, according to an embodiment of the present invention. As shown in <figref idrefs="DRAWINGS">FIG. 4A-B</figref>, as camera entrance pupils get closer together, the spatial parallax between the cameras decreases. Diagram <b>500</b> shows how to time the exposure of the cameras during motion of the vehicle so that each of the cameras is exposed when its entrance pupil is located at approximately the same location. As result, in diagram <b>500</b> the motion parallax caused by the moving vehicle reduces the spatial parallax due to multiple cameras.</p>
<p id="p-0056" num="0055">Diagram <b>500</b> shows a portion of a camera rosette at three positions <b>510</b>, <b>520</b>, <b>530</b> at three different points in time. The camera rosette shown has three cameras <b>502</b>, <b>504</b>, and <b>506</b> shown. Cameras <b>502</b>, <b>504</b>, and <b>506</b> have entrance pupils <b>508</b>, <b>514</b>, and <b>512</b> respectively. For clarity, only three cameras are shown. However, in practice a different number of cameras may be used (e.g. <b>8</b> horizontal cameras and 9 total cameras in another embodiment).</p>
<p id="p-0057" num="0056">In the embodiment in <figref idrefs="DRAWINGS">FIG. 5</figref>, the image sensors may or may not have rolling shutters. The embodiment may be useful with rolling shutters. However, the embodiment may also reduce parallax with image sensors having “global” shutter, such as an interline CCD or an image sensor using a mechanical shutter. The image capture is described as happening at an instant, even though there will be some exposure duration and a small motion blur as a result. At position <b>510</b>, camera <b>502</b> captures an image. At position <b>510</b>, camera <b>502</b>'s entrance pupil <b>508</b> is at a location <b>524</b>. Each subsequent camera is timed to take an image when that camera's entrance pupil is approximately located at location <b>524</b>.</p>
<p id="p-0058" num="0057">During a later point in time as the vehicle is moving, the camera rosette reaches position <b>520</b>. At position <b>520</b>, entrance pupil <b>514</b> of camera <b>504</b> is approximately at location <b>524</b>. At this point, camera <b>504</b> captures an image. Finally, at position <b>530</b> entrance pupil <b>512</b> of camera <b>506</b> reaches approximately location <b>524</b>, and camera <b>506</b> captures an image.</p>
<p id="p-0059" num="0058">The approximation may be due to inaccuracies in the vehicles velocity, or changes to the vehicle's direction. In an example, the approximation may be based on an average vehicle velocity as opposed to the actual velocity over the relevant period. Also, the approximation may be due to the fact that cameras are positioned two or three dimensionally on the camera rosette, whereas the movement of the rosette (e.g., on a vehicle) may be in only one direction. For example, in <figref idrefs="DRAWINGS">FIG. 5</figref> entrance pupil <b>508</b> is not at precisely the same location as entrance pupil <b>514</b> because entrance pupil <b>508</b> are entrance pupil <b>514</b> are at different locations on the axis perpendicular to the axis of motion.</p>
<p id="p-0060" num="0059">In another embodiment, a virtual plane is perpendicular to the direction of motion of a camera rosette. Each camera in a camera rosette may expose when an entrance pupil of the camera passes through the plane. In this way, each camera exposes when its entrance pupil is at approximately the same location, reducing parallax.</p>
<p id="p-0061" num="0060">As noted earlier, the time to trigger each subsequent camera may be calculated according to vehicle velocity and a distance between the cameras, such as a distance <b>522</b>. In the example shown, the delay from a time when camera <b>504</b> captures an image and a time when camera <b>506</b> captures an image is distance <b>522</b> divided by the vehicle's velocity. Supposing distance <b>522</b> was 10 cm and the vehicle velocity was 10 m/s, then the delay between the time when camera <b>504</b> captures an image and the time when camera <b>506</b> captures an image would be 10 ms. In other words, the further rear camera (camera <b>506</b>) starts to capture an image 10 ms after the more forward camera (camera <b>504</b>).</p>
<p id="p-0062" num="0061">As mentioned earlier, a vehicle velocity used to time the cameras may be an average vehicle velocity. Alternatively, the vehicle velocity may be determined in real time by a speedometer, a wheel encoder, or a GPS sensor. The velocity may be signaled to controllers in the cameras, which adjust the timing accordingly.</p>
<p id="p-0063" num="0062">In a preferred embodiment, the features shown in diagram <b>500</b> may be used in conjunction with the features described with respect to <figref idrefs="DRAWINGS">FIGS. 2A-C</figref>. <figref idrefs="DRAWINGS">FIG. 2B</figref> describes timing camera exposure in a camera rosette where each camera includes a rolling-shutter CMOS sensor in portrait orientation. In that embodiment, each camera is timed to start exposure when the previous camera begins to scan an region where their fields of view overlap at a distance. Describing the embodiment with respect to <figref idrefs="DRAWINGS">FIG. 2B</figref>, a delay between when camera <b>202</b> starts exposure and when camera <b>210</b> starts exposure substantially satisfies the equation:</p>
<p id="p-0064" num="0063">
<maths id="MATH-US-00001" num="00001">
<math overflow="scroll">
<mrow>
<mrow>
<mi>t</mi>
<mo>=</mo>
<mrow>
<mrow>
<msub>
<mi>R</mi>
<mn>1</mn>
</msub>
<mo>·</mo>
<msub>
<mi>F</mi>
<mn>1</mn>
</msub>
</mrow>
<mo>-</mo>
<mfrac>
<msub>
<mi>D</mi>
<mn>12</mn>
</msub>
<mi>v</mi>
</mfrac>
</mrow>
</mrow>
<mo>,</mo>
</mrow>
</math>
</maths>
</p>
<p id="p-0065" num="0064">where t is the delay time, R<sub>1 </sub>is a rolling-shutter readout time of the first image sensor, F<sub>1 </sub>is a percentage of the field of view of the first image sensor which does not overlap with the field of view of the second image sensor, D<sub>12 </sub>is a distance between an entrance pupil of the first image sensor and an entrance pupil of the second image sensor, and v is a speed of the camera apparatus. It would be recognized that small changes such as small offsets and coefficients may be added to this equation.</p>
<p id="p-0066" num="0065">In an example given with respect to <figref idrefs="DRAWINGS">FIG. 2B</figref>, overlap field of view <b>222</b> between camera <b>202</b> and camera <b>210</b> may be 10% of the total field of view of camera <b>202</b>. In that example, 90% of camera <b>202</b>'s field of view does not overlap with camera <b>210</b>'s field of view. In an example where camera <b>202</b>'s readout time is 100 ms, the delay between the time when camera <b>202</b> starts exposure and the time when camera <b>210</b> starts exposure may be 90 ms. In other words, the more forward camera (camera <b>210</b>) starts to capture an image 90 ms after the further rear camera starts to capture an image (camera <b>202</b>). As a result, cameras with overlapping fields of view capture images of objects in their overlap region at the same time, or from the same vehicle position. This timing is a first-order correction for parallax, in that it prevents the large parallax errors that would result if the objects in the overlap area were captured at very different times and very different vehicle positions, as would happen if the cameras started their rolling shutters simultaneously. However, there remains a smaller parallax error due to the entrance pupils of the cameras not being in the same place.</p>
<p id="p-0067" num="0066">In an example of the embodiment incorporating both features in diagram <b>500</b> and <figref idrefs="DRAWINGS">FIGS. 2A-C</figref>, the delay time is offset to further reduce spatial parallax. In the example given with respect to <figref idrefs="DRAWINGS">FIG. 5</figref>, the further rear camera (camera <b>506</b>) starts to capture an image 10 ms after the more forward camera (camera <b>504</b>). In the example in <figref idrefs="DRAWINGS">FIGS. 2A-C</figref>, the more forward camera (camera <b>210</b>) starts to capture an image 90 ms after the further rear camera starts to capture an image (camera <b>202</b>). In the combined embodiment, the 90 ms delay is offset by 10 ms. Therefore, the more forward camera starts to capture an image 80 ms after the further rear camera starts to capture an image. This embodiment has reduced spatial parallax, accounting jointly for rolling-shutter readout delay, vehicle velocity, and entrance pupil separation.</p>
<p id="p-0068" num="0067">In another embodiment, the timing offsets for reduced spatial parallax may only be applied to some of the cameras in a camera rosette. In an example, the offset may be applied to only those cameras pointed sideways from the vehicle motion. The cameras pointed sideways may be the cameras where typical vehicle motion moves the location of the entrance pupil of the more rear camera into the location where the camera took an image in, for example, 0.01 s or less. In this example, spatial parallax of forward-looking and backward-looking portions of the panorama may not be cancelled by motion parallax, but objects in these directions tend to be distant enough to not have a large parallax problem.</p>
<p id="p-0069" num="0068">As an alternative embodiment, a rolling shutter with a very fast readout time may be useful. As the shutter readout time becomes faster, the delay computed to account for the rolling shutter (as described in <figref idrefs="DRAWINGS">FIGS. 2A-C</figref>) decreases. So, at a particular readout time, the delay for the rolling shutter and the offset to account for spatial parallax may cancel each other out. This readout time is the time it takes for the vehicle to move forward a distance equal to the distance between entrance pupils. In an example, a readout time of a first image sensor may be 10 ms. Ninety percent of the first image sensor's field of view may not overlap with a second, next forward-most image sensor. If the vehicle is stationary, the delay time between exposure of the first and second image sensor would be 9 ms. However, if the vehicle is moving at 9 m/s and the distance between the first and second image sensor is 10 cm, then the delay offset due to motion of the vehicle would also be 9 ms. Thus, the offsets would effectively cancel each other out. Similarly, an image sensor with a variable rolling readout time may be used. In that instance, the readout time may be adjusted according to a speed of the vehicle.</p>
<p id="p-0070" num="0069"> <figref idrefs="DRAWINGS">FIG. 6</figref> shows a camera rosette <b>604</b> affixed to a vehicle <b>602</b>. Camera rosette <b>604</b> includes numerous cameras, such as a camera <b>606</b>. In an example, camera rosette <b>604</b> may be used to capture panoramic images of buildings running along a street.</p>
<p id="p-0071" num="0070">Each of the cameras in the camera rosette is coupled to a controller <b>608</b>. As mentioned earlier, controller <b>608</b> controls the timing of the exposure of each camera. Controller <b>608</b> may receive an input indicating a speed of the vehicle. Alternatively, controller <b>608</b> may be preprogrammed with timing offsets, such as offsets based on an average speed of the vehicle. A single controller <b>608</b> may be used. Alternatively, each camera may have its own controller.</p>
<p id="p-0072" num="0071">Controller <b>608</b> may be implemented in hardware, software, firmware, or any combination thereof. Controller <b>608</b> may be, for example, a general purpose computer running software to control the cameras' exposure. Controller <b>608</b> may have a processor and memory.</p>
<p id="p-0073" num="0072">The Summary and Abstract sections may set forth one or more but not all exemplary embodiments of the present invention as contemplated by the inventor(s), and thus, are not intended to limit the present invention and the appended claims in any way.</p>
<p id="p-0074" num="0073">The foregoing description of the specific embodiments will so fully reveal the general nature of the invention that others can, by applying knowledge within the skill of the art, readily modify and/or adapt for various applications such specific embodiments, without undue experimentation, without departing from the general concept of the present invention. Therefore, such adaptations and modifications are intended to be within the meaning and range of equivalents of the disclosed embodiments, based on the teaching and guidance presented herein. It is to be understood that the phraseology or terminology herein is for the purpose of description and not of limitation, such that the terminology or phraseology of the present specification is to be interpreted by the skilled artisan in light of the teachings and guidance.</p>
<p id="p-0075" num="0074">The breadth and scope of the present invention should not be limited by any of the above-described exemplary embodiments, but should be defined only in accordance with the following claims and their equivalents.</p>
</div>
</div>
</section>